{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_model_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1jdzNaMDwFBd-YZ1d5LBMp4WL2eFKGpkU",
      "authorship_tag": "ABX9TyM+ejORivCi5YnSbA+pYERC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sameepshrestha/Mission-Chatbot/blob/main/lstm_model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK872g-oMSg4"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import csv \n",
        "import pandas as pd \n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.activations import  sigmoid, tanh\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np \n",
        "from sklearn.preprocessing import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "-RtgWiym7Zhc",
        "outputId": "52535443-67d0-451f-a5a8-22f7437fc416"
      },
      "source": [
        "# encoder and decoder both input_shape = [batch ,time_step,feature] \n",
        "batch_size = 64\n",
        "time_step = 31\n",
        "feature  = 300  #the loss we wil be using is the cosine \n",
        "#the ct and the ht learned from the encoder as a context is passed to the decoder \n",
        "data_set = pd.read_csv('/content/drive/MyDrive/chat bots/trainable_dataset.csv')\n",
        "data_set.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>From</th>\n",
              "      <th>Message</th>\n",
              "      <th>reply</th>\n",
              "      <th>clean_message</th>\n",
              "      <th>clean_reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Puspa Rai</td>\n",
              "      <td>O ho k x hou</td>\n",
              "      <td>Thik. Xa</td>\n",
              "      <td>o ho k x hou</td>\n",
              "      <td>thik xa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Dipesh Chapagain</td>\n",
              "      <td>Hi Science test tomarrow</td>\n",
              "      <td>hlo \\ni am a friend of sameep...</td>\n",
              "      <td>hi science test tomarrow</td>\n",
              "      <td>hlo i am a friend of sameep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Spponge Bob</td>\n",
              "      <td>hhahaha sale malai k taha :D talai taha theyo ...</td>\n",
              "      <td>Ah ta aja tst ma gad</td>\n",
              "      <td>haha sale malai k taha d talai taha theyo jas...</td>\n",
              "      <td>ah ta aja tst ma gad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Spponge Bob</td>\n",
              "      <td>hhahahhaa k test ma pass hunxas ta :D</td>\n",
              "      <td>Xup pas ta humxu ful marks audaina bujis</td>\n",
              "      <td>haha k test ma pass hunxas ta d</td>\n",
              "      <td>xup pas ta humxu ful marks audaina bujis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Spponge Bob</td>\n",
              "      <td>hhahhaha :D :D sale maile tero wall pic hali d...</td>\n",
              "      <td>Ha kasari xange hanu pas</td>\n",
              "      <td>haha d d sale maile tero wall pic hali daeko ...</td>\n",
              "      <td>ha kasari xange hanu pas</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                clean_reply\n",
              "0           0  ...                                    thik xa\n",
              "1           1  ...                hlo i am a friend of sameep\n",
              "2           2  ...                       ah ta aja tst ma gad\n",
              "3           3  ...   xup pas ta humxu ful marks audaina bujis\n",
              "4           4  ...                   ha kasari xange hanu pas\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9TLVpGr1qDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f93d60-b237-42f7-d60e-b64f696d8e16"
      },
      "source": [
        "\n",
        "vocab = {}\n",
        "with open ('/content/drive/MyDrive/chat bots/metadata (1).tsv') as f:\n",
        "    for i,row in enumerate(csv.reader(f )):\n",
        "        vocab[row[0]] = i\n",
        "len(vocab)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38534"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTctAe9i1_FB"
      },
      "source": [
        "vectors = {}\n",
        "with open ('/content/drive/MyDrive/chat bots/vectors (1).tsv') as f:\n",
        "    for i,row in enumerate(csv.reader(f,delimiter=\"\\t\")):\n",
        "        vectors[i] = row "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxZ-RZfa72Nf"
      },
      "source": [
        "sequence_length =  31\n",
        "encoder_inputs = Input(shape=(None, sequence_length))\n",
        "encoder = LSTM(300, return_sequences=False, return_state=True)\n",
        "encoder_outputs, stateh, statec = encoder(encoder_inputs)\n",
        "encoder_states = [stateh,statec]\n",
        "decoder_inputs = Input(shape= (None, sequence_length))\n",
        "decoder = LSTM(300,return_sequences=True, return_state=True )\n",
        "decoder_outputs,_ ,_  = decoder(decoder_inputs, initial_state = encoder_states)\n",
        "\n",
        "decoder_dense = Dense(sequence_length, activation = tanh)\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "seq2seq_model = Model([encoder_inputs,decoder_inputs],decoder_outputs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFCeQS2-369_"
      },
      "source": [
        "cosine_loss = tf.compat.v1.losses.cosine_distance(axis=1)\n",
        "def loss_function(actual, output):\n",
        "    loss = 1-cosine_loss(actual, output)\n",
        "    return loss\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpmOmRqGpWKV"
      },
      "source": [
        "opt = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "seq2seq_mode.compile(optimizer=opt, loss = loss_function)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov_ljJSKU4wX"
      },
      "source": [
        " \n",
        "def encode_the_data (data):\n",
        "    total_data=[]\n",
        "    for line in data:\n",
        "        vocab_index = []\n",
        "        for words in line.split():\n",
        "            vocab_index.append(vocab[words])\n",
        "        total_data.append(vocab_index)\n",
        "    return (total_data)\n",
        "def vectorize (data):\n",
        "    total_data = []\n",
        "    for line in data:\n",
        "        vocab_index = []\n",
        "        for words in line:\n",
        "            vocab_index.append(vectors[words])\n",
        "        total_data.append(vocab_index)\n",
        "    return (total_data)\n",
        "def compile_data(data):\n",
        "    data = encode_the_data(data)\n",
        "    if \n",
        "    data = tf.keras.preprocessing.sequence.pad_sequences(data,maxlen=30,padding='pre')\n",
        "    data = vectorize(data)\n",
        "    return data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKtQ76ks6IRV"
      },
      "source": [
        "\n",
        "def train(x,y,batch_size,epochs):\n",
        "    train_dataset = tf.data.dataset.from_tensor_slices((train_x,train_y)).batch(batch_size).shuffle(45)\n",
        "    test_dataset = tf.data.dataset.from_tensor_slice((test_x,test_y))\n",
        "    for i in epochs:\n",
        "        for _, train_data in enumerate(dataset):\n",
        "            model.train(train_data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh2XSPOGhgV8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}